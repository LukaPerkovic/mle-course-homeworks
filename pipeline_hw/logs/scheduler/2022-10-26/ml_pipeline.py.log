[2022-10-26T15:37:22.792+0000] {processor.py:156} INFO - Started process (PID=162) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:37:22.847+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:37:22.848+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:37:22.848+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:37:24.196+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:37:24.155+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:37:24.197+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:37:24.269+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.483 seconds
[2022-10-26T15:37:54.765+0000] {processor.py:156} INFO - Started process (PID=168) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:37:54.768+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:37:54.774+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:37:54.774+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:37:56.222+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:37:56.206+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:37:56.224+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:37:56.398+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.686 seconds
[2022-10-26T15:38:26.939+0000] {processor.py:156} INFO - Started process (PID=173) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:38:26.945+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:38:26.953+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:38:26.953+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:38:27.980+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:38:27.967+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:38:27.983+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:38:28.086+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.152 seconds
[2022-10-26T15:38:58.301+0000] {processor.py:156} INFO - Started process (PID=178) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:38:58.306+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:38:58.308+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:38:58.308+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:38:59.064+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:38:59.050+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:38:59.066+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:38:59.331+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.048 seconds
[2022-10-26T15:39:29.546+0000] {processor.py:156} INFO - Started process (PID=183) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:39:29.550+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:39:29.551+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:39:29.551+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:39:29.638+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:39:29.633+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:39:29.639+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:39:29.670+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.130 seconds
[2022-10-26T15:39:59.887+0000] {processor.py:156} INFO - Started process (PID=188) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:39:59.888+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:39:59.890+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:39:59.890+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:40:00.040+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:40:00.037+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:40:00.041+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:40:00.095+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.213 seconds
[2022-10-26T15:40:30.262+0000] {processor.py:156} INFO - Started process (PID=193) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:40:30.265+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:40:30.266+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:40:30.266+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:40:38.443+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:40:38.387+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:40:38.444+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:40:38.555+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 8.297 seconds
[2022-10-26T15:41:08.941+0000] {processor.py:156} INFO - Started process (PID=198) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:41:08.943+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:41:08.943+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:41:08.943+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:41:09.703+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:41:09.703+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:41:09.767+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:41:09.905+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.968 seconds
[2022-10-26T15:41:40.422+0000] {processor.py:156} INFO - Started process (PID=203) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:41:40.435+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:41:40.436+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:41:40.436+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:41:41.208+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:41:41.207+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:41:41.209+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:41:41.267+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.848 seconds
[2022-10-26T15:42:11.550+0000] {processor.py:156} INFO - Started process (PID=208) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:42:11.553+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T15:42:11.554+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:42:11.554+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:42:11.925+0000] {logging_mixin.py:117} INFO - [2022-10-26T15:42:11.924+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 37
    else:
       ^
SyntaxError: invalid syntax
[2022-10-26T15:42:11.925+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T15:42:11.947+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.401 seconds
[2022-10-26T17:21:52.855+0000] {processor.py:156} INFO - Started process (PID=162) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:21:52.931+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:21:52.931+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:21:52.931+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:21:54.071+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:21:54.070+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 29
    to_drop = soil_cols + wilderness_cols + hillshade_cols
                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
[2022-10-26T17:21:54.082+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:21:54.110+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.327 seconds
[2022-10-26T17:22:24.621+0000] {processor.py:156} INFO - Started process (PID=168) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:22:24.650+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:22:24.653+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:22:24.653+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:22:25.114+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:22:25.102+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 29
    to_drop = soil_cols + wilderness_cols + hillshade_cols
                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
[2022-10-26T17:22:25.114+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:22:25.289+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.779 seconds
[2022-10-26T17:22:55.875+0000] {processor.py:156} INFO - Started process (PID=173) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:22:55.894+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:22:55.902+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:22:55.901+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:22:57.328+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:22:57.314+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 29
    to_drop = soil_cols + wilderness_cols + hillshade_cols
                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
[2022-10-26T17:22:57.330+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:22:57.421+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.553 seconds
[2022-10-26T17:23:28.089+0000] {processor.py:156} INFO - Started process (PID=178) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:23:28.113+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:23:28.114+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:23:28.114+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:23:28.671+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:23:28.662+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 29
    to_drop = soil_cols + wilderness_cols + hillshade_cols
                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
[2022-10-26T17:23:28.671+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:23:28.796+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.720 seconds
[2022-10-26T17:23:59.399+0000] {processor.py:156} INFO - Started process (PID=183) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:23:59.435+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:23:59.436+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:23:59.436+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:24:00.683+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:24:00.608+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 29
    to_drop = soil_cols + wilderness_cols + hillshade_cols
                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
[2022-10-26T17:24:00.683+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:24:00.948+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.570 seconds
[2022-10-26T17:24:31.164+0000] {processor.py:156} INFO - Started process (PID=188) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:24:31.170+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:24:31.171+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:24:31.171+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:24:31.930+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:24:31.925+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 29
    to_drop = soil_cols + wilderness_cols + hillshade_cols
                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
[2022-10-26T17:24:31.931+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:24:32.043+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.882 seconds
[2022-10-26T17:25:02.485+0000] {processor.py:156} INFO - Started process (PID=193) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:25:02.490+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:25:02.491+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:25:02.491+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:25:11.112+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:25:11.111+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 29
    to_drop = soil_cols + wilderness_cols + hillshade_cols
                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
[2022-10-26T17:25:11.112+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:25:11.160+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 8.704 seconds
[2022-10-26T17:25:41.464+0000] {processor.py:156} INFO - Started process (PID=198) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:25:41.477+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:25:41.487+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:25:41.487+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:25:48.385+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:25:48.185+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:25:48.825+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:25:49.151+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 7.743 seconds
[2022-10-26T17:26:19.765+0000] {processor.py:156} INFO - Started process (PID=211) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:26:19.787+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:26:19.792+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:26:19.792+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:26:24.390+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:26:24.389+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:26:24.392+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:26:24.435+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 4.673 seconds
[2022-10-26T17:28:07.534+0000] {processor.py:156} INFO - Started process (PID=162) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:28:07.537+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:28:07.538+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:28:07.538+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:28:09.837+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:28:09.836+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:28:09.838+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:28:09.879+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 2.388 seconds
[2022-10-26T17:28:40.111+0000] {processor.py:156} INFO - Started process (PID=176) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:28:40.115+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:28:40.116+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:28:40.116+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:28:43.466+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:28:43.465+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:28:43.467+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:28:43.570+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 3.485 seconds
[2022-10-26T17:29:14.535+0000] {processor.py:156} INFO - Started process (PID=189) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:29:14.554+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:29:14.662+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:29:14.632+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:29:25.771+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:29:25.763+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:29:25.772+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:29:25.867+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 11.337 seconds
[2022-10-26T17:29:56.143+0000] {processor.py:156} INFO - Started process (PID=202) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:29:56.145+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:29:56.145+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:29:56.145+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:29:59.213+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:29:59.212+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:29:59.214+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:29:59.281+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 3.145 seconds
[2022-10-26T17:30:29.477+0000] {processor.py:156} INFO - Started process (PID=215) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:30:29.478+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:30:29.480+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:30:29.480+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:30:30.425+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:30:30.424+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:30:30.426+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:30:30.447+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.975 seconds
[2022-10-26T17:31:00.654+0000] {processor.py:156} INFO - Started process (PID=228) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:31:00.658+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:31:00.659+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:31:00.659+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:31:01.626+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:31:01.625+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:31:01.626+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:31:01.676+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.026 seconds
[2022-10-26T17:31:32.004+0000] {processor.py:156} INFO - Started process (PID=241) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:31:32.026+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:31:32.027+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:31:32.027+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:31:36.679+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:31:36.678+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:31:36.711+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:31:37.022+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 5.054 seconds
[2022-10-26T17:32:07.946+0000] {processor.py:156} INFO - Started process (PID=254) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:32:07.954+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:32:07.954+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:32:07.954+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:32:11.399+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:32:11.398+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:32:11.400+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:32:11.485+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 3.548 seconds
[2022-10-26T17:32:41.798+0000] {processor.py:156} INFO - Started process (PID=267) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:32:41.811+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:32:41.812+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:32:41.812+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:32:42.965+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:32:42.964+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:32:42.966+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:32:43.008+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.215 seconds
[2022-10-26T17:33:13.494+0000] {processor.py:156} INFO - Started process (PID=280) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:33:13.505+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:33:13.506+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:33:13.506+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:33:14.413+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:33:14.413+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:33:14.414+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:33:14.449+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.958 seconds
[2022-10-26T17:33:44.662+0000] {processor.py:156} INFO - Started process (PID=293) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:33:44.663+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:33:44.664+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:33:44.664+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:33:45.339+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:33:45.338+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:33:45.340+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:33:45.417+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.758 seconds
[2022-10-26T17:34:15.621+0000] {processor.py:156} INFO - Started process (PID=306) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:34:15.622+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:34:15.622+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:34:15.622+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:34:16.339+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:34:16.337+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:34:16.339+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:34:16.409+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.792 seconds
[2022-10-26T17:34:46.669+0000] {processor.py:156} INFO - Started process (PID=319) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:34:46.671+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:34:46.671+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:34:46.671+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:34:47.766+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:34:47.765+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:34:47.767+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:34:47.837+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.179 seconds
[2022-10-26T17:35:17.957+0000] {processor.py:156} INFO - Started process (PID=332) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:35:17.969+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:35:17.970+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:35:17.970+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:35:18.871+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:35:18.870+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:35:18.872+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:35:18.899+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.946 seconds
[2022-10-26T17:35:49.198+0000] {processor.py:156} INFO - Started process (PID=345) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:35:49.200+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:35:49.200+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:35:49.200+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:35:50.738+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:35:50.737+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:35:50.739+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:35:50.781+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.599 seconds
[2022-10-26T17:36:20.993+0000] {processor.py:156} INFO - Started process (PID=358) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:36:20.995+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:36:20.995+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:36:20.995+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:36:21.657+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:36:21.656+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:36:21.658+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:36:21.681+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.692 seconds
[2022-10-26T17:36:51.926+0000] {processor.py:156} INFO - Started process (PID=371) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:36:51.927+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:36:51.928+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:36:51.928+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:36:52.865+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:36:52.864+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:36:52.866+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:36:52.910+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.988 seconds
[2022-10-26T17:37:23.227+0000] {processor.py:156} INFO - Started process (PID=384) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:37:23.229+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:37:23.230+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:37:23.230+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:37:23.808+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:37:23.807+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:37:23.809+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:37:23.833+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.610 seconds
[2022-10-26T17:37:54.112+0000] {processor.py:156} INFO - Started process (PID=397) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:37:54.121+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:37:54.122+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:37:54.122+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:37:56.094+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:37:56.092+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:37:56.095+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:37:56.139+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 2.045 seconds
[2022-10-26T17:38:26.324+0000] {processor.py:156} INFO - Started process (PID=410) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:38:26.326+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:38:26.327+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:38:26.327+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:38:26.946+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:38:26.945+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:38:26.954+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:38:27.004+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.684 seconds
[2022-10-26T17:38:57.185+0000] {processor.py:156} INFO - Started process (PID=423) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:38:57.192+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:38:57.194+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:38:57.194+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:38:57.923+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:38:57.922+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:38:57.924+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:38:57.963+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.782 seconds
[2022-10-26T17:39:28.070+0000] {processor.py:156} INFO - Started process (PID=436) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:39:28.073+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:39:28.073+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:39:28.073+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:39:28.878+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:39:28.877+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 10, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:39:28.879+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:39:28.914+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.854 seconds
[2022-10-26T17:39:53.350+0000] {processor.py:156} INFO - Started process (PID=449) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:39:53.353+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:39:53.354+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:39:53.354+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:39:54.210+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:39:54.209+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:39:54.211+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:39:54.235+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.888 seconds
[2022-10-26T17:40:24.450+0000] {processor.py:156} INFO - Started process (PID=462) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:40:24.454+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:40:24.454+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:40:24.454+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:40:25.070+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:40:25.068+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:40:25.071+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:40:25.095+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.649 seconds
[2022-10-26T17:40:55.277+0000] {processor.py:156} INFO - Started process (PID=475) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:40:55.280+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:40:55.281+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:40:55.281+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:40:55.891+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:40:55.890+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:40:55.892+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:40:55.918+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.646 seconds
[2022-10-26T17:41:26.145+0000] {processor.py:156} INFO - Started process (PID=488) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:41:26.147+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:41:26.153+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:41:26.152+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:41:29.127+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:41:29.126+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:41:29.128+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:41:29.155+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 3.027 seconds
[2022-10-26T17:41:59.346+0000] {processor.py:156} INFO - Started process (PID=501) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:41:59.349+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:41:59.349+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:41:59.349+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:41:59.937+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:41:59.936+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:41:59.939+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:41:59.963+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.620 seconds
[2022-10-26T17:42:30.156+0000] {processor.py:156} INFO - Started process (PID=514) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:42:30.168+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:42:30.175+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:42:30.175+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:42:30.757+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:42:30.755+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:42:30.757+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:42:30.783+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.631 seconds
[2022-10-26T17:43:00.978+0000] {processor.py:156} INFO - Started process (PID=527) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:43:00.981+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:43:00.981+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:43:00.981+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:43:01.741+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:43:01.738+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:43:01.742+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:43:01.790+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.816 seconds
[2022-10-26T17:43:32.039+0000] {processor.py:156} INFO - Started process (PID=540) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:43:32.042+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:43:32.043+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:43:32.042+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:43:32.626+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:43:32.625+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:43:32.627+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:43:32.656+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.621 seconds
[2022-10-26T17:44:02.839+0000] {processor.py:156} INFO - Started process (PID=553) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:44:02.841+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:44:02.842+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:44:02.842+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:44:03.527+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:44:03.526+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:44:03.528+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:44:03.563+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.728 seconds
[2022-10-26T17:44:33.780+0000] {processor.py:156} INFO - Started process (PID=566) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:44:33.781+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:44:33.782+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:44:33.782+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:44:34.346+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:44:34.344+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:44:34.346+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:44:34.387+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.613 seconds
[2022-10-26T17:45:04.587+0000] {processor.py:156} INFO - Started process (PID=579) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:45:04.599+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:45:04.600+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:45:04.600+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:45:05.880+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:45:05.879+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:45:05.881+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:45:05.920+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.336 seconds
[2022-10-26T17:45:36.086+0000] {processor.py:156} INFO - Started process (PID=592) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:45:36.089+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:45:36.089+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:45:36.089+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:45:36.659+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:45:36.657+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:45:36.661+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:45:36.717+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.635 seconds
[2022-10-26T17:53:08.286+0000] {processor.py:156} INFO - Started process (PID=162) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:53:08.310+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:53:08.318+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:53:08.317+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:53:11.523+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:53:11.522+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:53:11.523+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:53:11.570+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 3.322 seconds
[2022-10-26T17:53:41.898+0000] {processor.py:156} INFO - Started process (PID=176) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:53:41.924+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:53:41.924+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:53:41.924+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:53:44.139+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:53:44.138+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:53:44.139+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:53:44.250+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 2.355 seconds
[2022-10-26T17:54:14.692+0000] {processor.py:156} INFO - Started process (PID=189) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:54:14.701+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:54:14.710+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:54:14.709+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:54:19.782+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:54:19.781+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:54:19.782+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:54:19.845+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 5.156 seconds
[2022-10-26T17:54:50.024+0000] {processor.py:156} INFO - Started process (PID=202) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:54:50.025+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:54:50.032+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:54:50.032+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:54:52.065+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:54:52.064+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:54:52.066+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:54:52.140+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 2.122 seconds
[2022-10-26T17:55:22.519+0000] {processor.py:156} INFO - Started process (PID=215) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:55:22.524+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:55:22.526+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:55:22.526+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:55:27.306+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:55:27.303+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:55:27.308+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:55:27.338+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 4.901 seconds
[2022-10-26T17:55:57.702+0000] {processor.py:156} INFO - Started process (PID=228) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:55:57.703+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T17:55:57.703+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:55:57.703+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:55:59.030+0000] {logging_mixin.py:117} INFO - [2022-10-26T17:55:59.029+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T17:55:59.031+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T17:55:59.085+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.386 seconds
[2022-10-26T18:06:02.810+0000] {processor.py:156} INFO - Started process (PID=162) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:06:02.848+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:06:02.850+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:06:02.849+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:06:04.718+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:06:04.717+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:06:04.718+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:06:04.796+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.989 seconds
[2022-10-26T18:06:35.248+0000] {processor.py:156} INFO - Started process (PID=176) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:06:35.251+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:06:35.252+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:06:35.251+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:06:37.653+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:06:37.653+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:06:37.654+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:06:37.781+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 2.558 seconds
[2022-10-26T18:07:08.284+0000] {processor.py:156} INFO - Started process (PID=189) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:07:08.288+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:07:08.290+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:07:08.289+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:07:11.814+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:07:11.813+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:07:11.815+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:07:11.966+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 3.687 seconds
[2022-10-26T18:07:42.207+0000] {processor.py:156} INFO - Started process (PID=202) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:07:42.211+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:07:42.212+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:07:42.212+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:07:42.948+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:07:42.948+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:07:42.949+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:07:42.991+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.789 seconds
[2022-10-26T18:08:13.219+0000] {processor.py:156} INFO - Started process (PID=215) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:08:13.220+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:08:13.221+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:08:13.221+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:08:14.856+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:08:14.856+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:08:14.857+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:08:14.875+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.671 seconds
[2022-10-26T18:08:45.125+0000] {processor.py:156} INFO - Started process (PID=228) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:08:45.144+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:08:45.148+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:08:45.147+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:08:46.294+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:08:46.293+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:08:46.295+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:08:46.338+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.216 seconds
[2022-10-26T18:09:16.573+0000] {processor.py:156} INFO - Started process (PID=241) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:09:16.574+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:09:16.575+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:09:16.575+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:09:17.484+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:09:17.483+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:09:17.485+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:09:17.525+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.958 seconds
[2022-10-26T18:09:47.751+0000] {processor.py:156} INFO - Started process (PID=254) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:09:47.756+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:09:47.757+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:09:47.757+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:09:49.674+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:09:49.673+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:09:49.675+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:09:49.770+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 2.021 seconds
[2022-10-26T18:10:20.110+0000] {processor.py:156} INFO - Started process (PID=267) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:10:20.126+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:10:20.127+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:10:20.127+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:10:22.133+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:10:22.131+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:10:22.133+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:10:22.158+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 2.058 seconds
[2022-10-26T18:10:52.457+0000] {processor.py:156} INFO - Started process (PID=280) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:10:52.503+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T18:10:52.504+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:10:52.503+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:10:54.767+0000] {logging_mixin.py:117} INFO - [2022-10-26T18:10:54.766+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 106, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2022-10-26T18:10:54.780+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T18:10:54.900+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 2.446 seconds
[2022-10-26T19:26:04.652+0000] {processor.py:156} INFO - Started process (PID=162) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:26:04.682+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T19:26:04.703+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:26:04.703+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:26:27.548+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:26:27.547+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 6, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T19:26:27.564+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:26:27.653+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 23.003 seconds
[2022-10-26T19:26:58.474+0000] {processor.py:156} INFO - Started process (PID=256) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:26:58.483+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T19:26:58.487+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:26:58.486+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:27:28.501+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:27:28.501+0000] {timeout.py:68} ERROR - Process timed out, PID: 256
[2022-10-26T19:27:28.511+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:27:28.503+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 256
[2022-10-26T19:27:28.516+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:27:28.515+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-26T19:27:28.573+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:27:28.519+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 256

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-10-26T19:27:28.577+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:27:28.577+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-10-26T19:27:28.590+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:27:28.578+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-10-26T19:27:28.631+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:27:29.066+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 30.595 seconds
[2022-10-26T19:28:00.166+0000] {processor.py:156} INFO - Started process (PID=314) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:28:00.177+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T19:28:00.221+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:28:00.220+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:28:30.286+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:28:30.285+0000] {timeout.py:68} ERROR - Process timed out, PID: 314
[2022-10-26T19:28:30.299+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:28:30.286+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 269, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 483, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 314
[2022-10-26T19:28:30.299+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:28:30.565+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 30.436 seconds
[2022-10-26T19:29:00.965+0000] {processor.py:156} INFO - Started process (PID=354) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:29:00.966+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T19:29:00.967+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:29:00.966+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:29:21.485+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:29:21.485+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 6, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T19:29:21.488+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:29:21.549+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 20.587 seconds
[2022-10-26T19:29:51.968+0000] {processor.py:156} INFO - Started process (PID=447) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:29:51.970+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T19:29:51.973+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:29:51.973+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:30:13.856+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:30:13.856+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 6, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T19:30:13.861+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:30:14.049+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 22.105 seconds
[2022-10-26T19:30:44.201+0000] {processor.py:156} INFO - Started process (PID=540) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:30:44.216+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T19:30:44.217+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:30:44.217+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:30:57.123+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:30:57.122+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 6, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T19:30:57.136+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:30:57.199+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 13.002 seconds
[2022-10-26T19:31:27.438+0000] {processor.py:156} INFO - Started process (PID=633) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:31:27.439+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T19:31:27.440+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:31:27.440+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:31:40.404+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:31:40.403+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 6, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T19:31:40.404+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:31:40.536+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 13.103 seconds
[2022-10-26T19:32:10.822+0000] {processor.py:156} INFO - Started process (PID=726) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:32:10.825+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T19:32:10.825+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:32:10.825+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:32:26.852+0000] {logging_mixin.py:117} INFO - [2022-10-26T19:32:26.851+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 6, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T19:32:26.856+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T19:32:26.965+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 16.147 seconds
[2022-10-26T20:10:45.583+0000] {processor.py:156} INFO - Started process (PID=161) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:10:45.631+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:10:45.631+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:10:45.631+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:11:10.346+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:11:10.341+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 272, in getOrCreate
    session = SparkSession(sc, options=self._options)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 307, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc(), options)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 332, in get_return_value
    format(target_id, ".", name, value))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession. Trace:
py4j.Py4JException: Constructor org.apache.spark.sql.SparkSession([class org.apache.spark.SparkContext, class java.util.HashMap]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2022-10-26T20:11:10.346+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:11:10.399+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 24.818 seconds
[2022-10-26T20:11:40.612+0000] {processor.py:156} INFO - Started process (PID=250) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:11:40.628+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:11:40.630+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:11:40.630+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:12:05.207+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:12:05.206+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 272, in getOrCreate
    session = SparkSession(sc, options=self._options)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 307, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc(), options)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 332, in get_return_value
    format(target_id, ".", name, value))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession. Trace:
py4j.Py4JException: Constructor org.apache.spark.sql.SparkSession([class org.apache.spark.SparkContext, class java.util.HashMap]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2022-10-26T20:12:05.210+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:12:05.283+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 24.740 seconds
[2022-10-26T20:12:35.606+0000] {processor.py:156} INFO - Started process (PID=338) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:12:35.609+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:12:35.613+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:12:35.613+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:12:49.490+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:12:49.488+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 272, in getOrCreate
    session = SparkSession(sc, options=self._options)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 307, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc(), options)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 332, in get_return_value
    format(target_id, ".", name, value))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession. Trace:
py4j.Py4JException: Constructor org.apache.spark.sql.SparkSession([class org.apache.spark.SparkContext, class java.util.HashMap]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2022-10-26T20:12:49.491+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:12:49.534+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 13.936 seconds
[2022-10-26T20:13:19.822+0000] {processor.py:156} INFO - Started process (PID=426) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:13:19.824+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:13:19.835+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:13:19.835+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:13:43.016+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:13:43.015+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 272, in getOrCreate
    session = SparkSession(sc, options=self._options)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 307, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc(), options)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 332, in get_return_value
    format(target_id, ".", name, value))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession. Trace:
py4j.Py4JException: Constructor org.apache.spark.sql.SparkSession([class org.apache.spark.SparkContext, class java.util.HashMap]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2022-10-26T20:13:43.016+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:13:43.097+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 23.288 seconds
[2022-10-26T20:14:13.395+0000] {processor.py:156} INFO - Started process (PID=514) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:14:13.396+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:14:13.397+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:14:13.397+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:14:26.073+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:14:26.072+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 5, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 7, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 272, in getOrCreate
    session = SparkSession(sc, options=self._options)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 307, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc(), options)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 332, in get_return_value
    format(target_id, ".", name, value))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession. Trace:
py4j.Py4JException: Constructor org.apache.spark.sql.SparkSession([class org.apache.spark.SparkContext, class java.util.HashMap]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2022-10-26T20:14:26.077+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:14:26.373+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 12.992 seconds
[2022-10-26T20:30:14.273+0000] {processor.py:156} INFO - Started process (PID=162) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:30:14.284+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:30:14.285+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:30:14.284+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:30:15.256+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:30:15.255+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 4
    rom pyspark.sql import SparkSession
              ^
SyntaxError: invalid syntax
[2022-10-26T20:30:15.259+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:30:15.296+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.060 seconds
[2022-10-26T20:30:45.695+0000] {processor.py:156} INFO - Started process (PID=168) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:30:45.720+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:30:45.721+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:30:45.721+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:30:46.180+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:30:46.158+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 4
    rom pyspark.sql import SparkSession
              ^
SyntaxError: invalid syntax
[2022-10-26T20:30:46.180+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:30:46.252+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.560 seconds
[2022-10-26T20:31:17.134+0000] {processor.py:156} INFO - Started process (PID=173) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:31:17.149+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:31:17.157+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:31:17.156+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:31:18.563+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:31:18.520+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 4
    rom pyspark.sql import SparkSession
              ^
SyntaxError: invalid syntax
[2022-10-26T20:31:18.568+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:31:18.819+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.700 seconds
[2022-10-26T20:31:49.410+0000] {processor.py:156} INFO - Started process (PID=178) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:31:49.417+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:31:49.467+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:31:49.467+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:31:50.868+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:31:50.861+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 4
    rom pyspark.sql import SparkSession
              ^
SyntaxError: invalid syntax
[2022-10-26T20:31:50.868+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:31:51.015+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 1.643 seconds
[2022-10-26T20:32:21.451+0000] {processor.py:156} INFO - Started process (PID=183) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:32:21.460+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:32:21.460+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:32:21.460+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:32:21.624+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:32:21.618+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 4
    rom pyspark.sql import SparkSession
              ^
SyntaxError: invalid syntax
[2022-10-26T20:32:21.625+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:32:21.710+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 0.275 seconds
[2022-10-26T20:33:39.464+0000] {processor.py:156} INFO - Started process (PID=161) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:33:39.520+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:33:39.521+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:33:39.521+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:34:09.529+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:34:09.528+0000] {timeout.py:68} ERROR - Process timed out, PID: 161
[2022-10-26T20:34:09.531+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:34:09.529+0000] {java_gateway.py:1210} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1200, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 161
[2022-10-26T20:34:09.531+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:34:09.531+0000] {java_gateway.py:1051} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1200, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 161

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1033, in send_command
    response = connection.send_command(command)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1212, in send_command
    "Error while receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while receiving
[2022-10-26T20:34:09.532+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:34:09.531+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 8, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 10, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/usr/local/spark/python/pyspark/sql/session.py", line 233, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1305, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/usr/local/spark/python/pyspark/sql/utils.py", line 111, in deco
    return f(*a, **kw)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o24.sessionState
[2022-10-26T20:34:09.536+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:34:09.720+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 30.259 seconds
[2022-10-26T20:34:40.452+0000] {processor.py:156} INFO - Started process (PID=249) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:34:40.492+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:34:40.493+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:34:40.492+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:35:10.506+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:35:10.506+0000] {timeout.py:68} ERROR - Process timed out, PID: 249
[2022-10-26T20:35:10.531+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:35:10.511+0000] {java_gateway.py:1210} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1200, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 249
[2022-10-26T20:35:10.532+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:35:10.532+0000] {java_gateway.py:1051} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1200, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 249

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1033, in send_command
    response = connection.send_command(command)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1212, in send_command
    "Error while receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while receiving
[2022-10-26T20:35:10.535+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:35:10.534+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 8, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 10, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/usr/local/spark/python/pyspark/sql/session.py", line 233, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1305, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/usr/local/spark/python/pyspark/sql/utils.py", line 111, in deco
    return f(*a, **kw)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o24.sessionState
[2022-10-26T20:35:10.559+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:35:12.204+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 31.755 seconds
[2022-10-26T20:35:42.843+0000] {processor.py:156} INFO - Started process (PID=336) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:35:42.846+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:35:42.852+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:35:42.852+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:36:12.886+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:36:12.885+0000] {timeout.py:68} ERROR - Process timed out, PID: 336
[2022-10-26T20:36:12.888+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:36:12.886+0000] {java_gateway.py:1210} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1200, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 336
[2022-10-26T20:36:12.888+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:36:12.888+0000] {java_gateway.py:1051} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1200, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.1/best-practices.html#reducing-dag-complexity, PID: 336

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1033, in send_command
    response = connection.send_command(command)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1212, in send_command
    "Error while receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while receiving
[2022-10-26T20:36:12.889+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:36:12.888+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 8, in <module>
    from scripts.handle_file import read_file, save_file
  File "/opt/airflow/dags/scripts/handle_file.py", line 10, in <module>
    spark = SparkSession.builder.appName('Handling CSV files').getOrCreate()
  File "/usr/local/spark/python/pyspark/sql/session.py", line 233, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1305, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/usr/local/spark/python/pyspark/sql/utils.py", line 111, in deco
    return f(*a, **kw)
  File "/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o24.sessionState
[2022-10-26T20:36:12.889+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:36:13.133+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 30.301 seconds
[2022-10-26T20:36:43.612+0000] {processor.py:156} INFO - Started process (PID=423) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:36:43.624+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:36:43.631+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:36:43.630+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:37:09.195+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:37:09.194+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 9, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T20:37:09.198+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:37:09.223+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 25.614 seconds
[2022-10-26T20:37:39.512+0000] {processor.py:156} INFO - Started process (PID=510) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:37:39.522+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:37:39.525+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:37:39.525+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:37:57.083+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:37:57.083+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 9, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T20:37:57.084+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:37:57.108+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 17.618 seconds
[2022-10-26T20:38:27.153+0000] {processor.py:156} INFO - Started process (PID=597) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:38:27.155+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:38:27.155+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:38:27.155+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:38:40.598+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:38:40.598+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 11, in <module>
    from scripts.preprocess_data import preprocess_data
  File "/opt/airflow/dags/scripts/preprocess_data.py", line 9, in <module>
    from scripts.validate_data import validate_target_variable
  File "/opt/airflow/dags/scripts/validate_data.py", line 2
    from pyspark.sql
                   ^
SyntaxError: invalid syntax
[2022-10-26T20:38:40.599+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:38:40.636+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/ml_pipeline.py took 13.487 seconds
[2022-10-26T20:39:11.054+0000] {processor.py:156} INFO - Started process (PID=684) to work on /opt/airflow/dags/ml_pipeline.py
[2022-10-26T20:39:11.054+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/ml_pipeline.py for tasks to queue
[2022-10-26T20:39:11.055+0000] {logging_mixin.py:117} INFO - [2022-10-26T20:39:11.055+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/ml_pipeline.py
