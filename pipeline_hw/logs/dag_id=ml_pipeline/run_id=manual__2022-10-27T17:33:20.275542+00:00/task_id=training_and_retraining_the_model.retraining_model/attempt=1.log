[2022-10-27T17:33:29.907+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: ml_pipeline.training_and_retraining_the_model.retraining_model manual__2022-10-27T17:33:20.275542+00:00 [queued]>
[2022-10-27T17:33:30.014+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: ml_pipeline.training_and_retraining_the_model.retraining_model manual__2022-10-27T17:33:20.275542+00:00 [queued]>
[2022-10-27T17:33:30.014+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-10-27T17:33:30.014+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-10-27T17:33:30.014+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-10-27T17:33:30.250+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): training_and_retraining_the_model.retraining_model> on 2022-10-27 17:33:20.275542+00:00
[2022-10-27T17:33:30.527+0000] {standard_task_runner.py:54} INFO - Started process 218 to run task
[2022-10-27T17:33:30.770+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'ml_pipeline', 'training_and_retraining_the_model.retraining_model', 'manual__2022-10-27T17:33:20.275542+00:00', '--job-id', '93', '--raw', '--subdir', 'DAGS_FOLDER/ml_pipeline.py', '--cfg-path', '/tmp/tmppo0x9kad']
[2022-10-27T17:33:30.771+0000] {standard_task_runner.py:83} INFO - Job 93: Subtask training_and_retraining_the_model.retraining_model
[2022-10-27T17:33:30.772+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/ml_pipeline.py
[2022-10-27T17:34:01.544+0000] {timeout.py:68} ERROR - Process timed out, PID: 218
[2022-10-27T17:34:01.595+0000] {dagbag.py:330} ERROR - Failed to import: /opt/***/dags/ml_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/ml_pipeline.py", line 13, in <module>
    from scripts.train_model import train_model
  File "/opt/airflow/dags/scripts/train_model.py", line 5, in <module>
    from sklearn.ensemble import RandomForestClassifier
  File "/home/airflow/.local/lib/python3.7/site-packages/sklearn/ensemble/__init__.py", line 5, in <module>
    from ._base import BaseEnsemble
  File "/home/airflow/.local/lib/python3.7/site-packages/sklearn/ensemble/_base.py", line 18, in <module>
    from ..tree import DecisionTreeRegressor, ExtraTreeRegressor
  File "/home/airflow/.local/lib/python3.7/site-packages/sklearn/tree/__init__.py", line 6, in <module>
    from ._classes import BaseDecisionTree
  File "/home/airflow/.local/lib/python3.7/site-packages/sklearn/tree/_classes.py", line 41, in <module>
    from ._criterion import Criterion
  File "sklearn/tree/_criterion.pyx", line 1, in init sklearn.tree._criterion
  File "sklearn/tree/_splitter.pyx", line 1, in init sklearn.tree._splitter
  File "sklearn/tree/_tree.pyx", line 1, in init sklearn.tree._tree
  File "/home/airflow/.local/lib/python3.7/site-packages/sklearn/neighbors/__init__.py", line 6, in <module>
    from ._ball_tree import BallTree
  File "sklearn/neighbors/_ball_tree.pyx", line 1, in init sklearn.neighbors._ball_tree
  File "/home/airflow/.local/lib/python3.7/site-packages/sklearn/metrics/__init__.py", line 41, in <module>
    from . import cluster
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 857, in get_code
  File "<frozen importlib._bootstrap_external>", line 525, in _compile_bytecode
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/***/dags/ml_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://***.apache.org/docs/apache-***/2.4.1/best-practices.html#top-level-python-code
* https://***.apache.org/docs/apache-***/2.4.1/best-practices.html#reducing-dag-complexity, PID: 218
[2022-10-27T17:34:01.658+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 93 for task training_and_retraining_the_model.retraining_model (Dag 'ml_pipeline' could not be found; either it does not exist or it failed to parse.; 218)
[2022-10-27T17:34:02.288+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-10-27T17:34:02.751+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
